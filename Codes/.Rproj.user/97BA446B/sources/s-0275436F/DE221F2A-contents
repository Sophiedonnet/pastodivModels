---
title:  "SPDE - Air pollution example"
subtitle: Version 1.1
author: "Thomas Opitz et Denis Allard - BioSP"
date: "`r format(Sys.time(), '%d %B %Y')`"
always_allow_html: yes
fig_caption: true
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align="center",fig.width = 4)
#library(kableExtra)
```

# Introduction

This tutorial focuses on running INLA/SPDE, not on producing sound statistical analysis or fancy illustrations. We load the data object for 2014 daily pollution data over France measured on 378 stations. In this exercise, we do not use the CHIMERE predictions, which are gridded hindcasts based on physical-chemical transport model. We first load a few libraries that will be necessary. If R-INLA is not yet installed, uncomment the appropriate line and run the relevant `install.packages()` command.

```{r Loading libraries, echo=TRUE, tidy=TRUE, warning=FALSE, message=FALSE}
#install.packages("INLA",repos=c(getOption("repos"),INLA="https://inla.r-inla-download.org/R/stable"), dep=TRUE)
library(fields) #for plotting (image.plot)
library(INLA)
library(sp)
library(maps)
```


# Loading and mapping the data

We have a data frame with observations of daily PM10 and PM2.5 air pollutant concentrations at measurement stations. For the sake of easier analysis, we keep only background stations (not traffic/industry, which generate highly localized pollution patterns).

```{r Loading the data, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
load("OBS_2014.RData")
head(OBS_daily2014)
OBS_daily2014=OBS_daily2014[OBS_daily2014$type_of_station=="Background",]
print(c("dim(OBS_daily2014: ",dim(OBS_daily2014))) #more than 100,000 data points
dates=as.Date(OBS_daily2014$date)
OBS_daily2014$day=1+as.integer(difftime(OBS_daily2014$date,OBS_daily2014$date[1],units='days'))
```

We transform longitude-latitude to Lambert93-coordinates (which correspond to "real" distances over France). This is necessary for accurate modeling of the spatial dependence since the distance of one unit latitude is different from one unit longitude. We use the EPSG codes for projections (European Petroleum Survey Group): 

* 4326 for longitude-latitude;
* 2154 for Lambert93.

For the spatial unit, we use 1000km. This is useful for the SPDE functions in RINLA, which may have stability problems with very large coordinate values.

```{r Map the data, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
xy_OBS=SpatialPoints(coords=OBS_daily2014[,c("long","lat")],proj4string=CRS("+init=epsg:4326"))
xy_OBS=spTransform(xy_OBS,CRS("+init=epsg:2154"))@coords/10^6

# We prepare the boundary coordinates of the French territory:
fr=map("world",regions="france",plot=FALSE)

# Transform coordinates to Lambert 93 using spTransform:
xy_fr = SpatialPoints(coords=na.omit(cbind(fr$x,fr$y)),proj4string=CRS("+init=epsg:4326"))
xy_fr = spTransform(xy_fr,CRS("+init=epsg:2154"))@coords/10^6
fr$x[!is.na(fr$x)] = xy_fr[,1]
fr$y[!is.na(fr$y)] = xy_fr[,2]

# We plot observation sites and French territorial boundary:
plot(unique(xy_OBS),pch=19,cex=.33, asp = 1, xlab = "x (1000 km)", ylab = "y (1000 km)")
lines(fr$x,fr$y,lwd=2)
```


# First Model

We here use PM10 as our response variable. Later, we could also consider PM2.5, e.g. for bivariate modeling of PM10 and PM2.5.


Let's start with a simple model for spatial trends. We use a Gaussian SPDE field as prior for the trend surface. The choice of prior distribution for the spatial field is not easy here since it seems that even nearby observation stations have very different trends sometimes. Moreover, the model disregards spatial and temporal dependence, i.e., it is rather simplistic.
We further include $x$ and $y$ as linear covariates ("fixed effects"):


## Creating the mesh

First, we have to create a mesh (=triangulation of space). The Gaussian variables will be defined on the mesh nodes and are then interpolated linearly between the nodes.


```{r Create mesh, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
bound  = inla.nonconvex.hull(unique(xy_OBS),convex=-.05)
bound2 = inla.nonconvex.hull(unique(xy_OBS),convex=-.2)
plot(rbind(bound2$loc,bound2$loc[1,]),type="l", asp = 1, xlab = "x (1000 km)", ylab = "y (1000 km)")
lines(rbind(bound$loc,bound$loc[1,]))
points(unique(xy_OBS),pch=19,cex=.25)

# Define minimum edge length as 10km and maximum edge length as 25km 
# (within the study region) and 50km (in the extension zone).
mesh=inla.mesh.2d(loc=unique(xy_OBS),boundary=list(bound,bound2),cutoff=.01,
                  max.edge=c(.025,.5),min.angle=c(21,21))
print(c("Number of mesh:", mesh$n))
plot(mesh, asp = 1, xlab = "x (1000 km)", ylab = "y (1000 km)") #looks OK
lines(fr$x,fr$y,lwd=2,col="red") #add the true boundary of France in red
```

## Building the SPDE model with PC priors

We define an SPDE object with penalized complexity prior.  The distribution of the PC priors is unique for each parameter. It is expressed as a probability to deviate from a base case, which is a less complex model. For example for the variance parameter, the less complex model corresponds to $\sigma^2=0$. For the range parameter, the less complex model has an infinite range, since this would correspond to perfect dependence (hence less variability). The parameterization follows this idea: we indicate two values. The first value is a probability of being "more complex"; the second value is the quantile corresponding to this probability. Below, we set that probability of having range $<$ 10 km is 10%, and that the probability of having standard deviation larger than 25 is 50%. See documentation on PC priors for more details.

```{r Build SPDE model, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
myspde=inla.spde2.pcmatern(mesh=mesh,alpha=2,prior.range=c(.01,.1),prior.sigma=c(25,0.5))

# Observation matrix to make the connection between mesh nodes and observation sites:
A=inla.spde.make.A(mesh,loc=xy_OBS)

# Vector of indices for the nodes of the mesh
idx.spatial=inla.spde.make.index("spatial",n.spde=mesh$n)
```


## Building the regression part

First, we create covariate dataframe: we add the intercept term 1, since in `R-INLA` it's more comfortable to include the intercept explicitly.

```{r Build regression formula, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
covar.df=data.frame(intercept=1,x=xy_OBS[,1],y=xy_OBS[,2])

# Create the stack with all the data and indices:
mystack=inla.stack(data=list(pm10=OBS_daily2014$PM10),A=list(A,1),
                   effects=list(idx.spatial,covar.df))

# We write the formula for the model: 
myformula=pm10~-1+intercept+x+y+f(spatial,model=myspde)
```

Note: since we handle the intercept explicitly, we have to include "-1"). Coordinates x and y are included as covariates. Recall that we have given the name "spatial" to the index of the spatial effect.


# Running the INLA/SPDE model

## Running the function inla

Let's run the `inla` function. To avoid that `inla` becomes too greedy with memory and cpu, we may fix the maximum number of parallel threads to 2.

For faster calculations, we here use 
```{r echo=TRUE, eval=FALSE, warning=FALSE, message=FALSE, tidy=TRUE}
control.inla=list(int.strategy="eb",strategy="gaussian")
```
The default option would be 
```{r echo=TRUE, eval=FALSE, warning=FALSE, message=FALSE, tidy=TRUE}
control.inla=list(int.strategy="ccd",strategy="simplified.laplace")
```
The following `inla` run should take approximatively 1 minute. As an exercise, you can try `gamma` or `sn` instead of `gaussian`.

```{r Running my INLA/SPDE model, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
num.thr=2 #number of threads that INLA is allowed to run in parallel
fit=inla(myformula,
         data=inla.stack.data(mystack),
         family="gaussian",
         control.predictor=list(A=inla.stack.A(mystack),compute=FALSE),
         control.inla=list(int.strategy="eb",strategy="gaussian"),
         verbose=FALSE,
         num.threads=num.thr
         )
summary(fit)
``` 


We observe very high standard errors for fixed effects. That's a bit weird. We should probably remove $x$ and $y$ which do not seem to contain useful information here: refit the model without fixed effects of coordinates $x$ and $y$: 

```{r Running a better INLA/SPDE model, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
myformula=pm10~-1+intercept+f(spatial,model=myspde)
fit=inla(myformula,
         data=inla.stack.data(mystack),
         family="gaussian", 
         control.predictor=list(A=inla.stack.A(mystack),compute=FALSE),
         control.inla=list(int.strategy="eb",strategy="gaussian"),
         verbose=FALSE,
         num.threads=num.thr
)
summary(fit)
``` 

The standard error for intercept looks more reasonable now. The range of spatial effect is approximately 20km (there will be very little smoothing over space in the estimated model.)
The standard deviation of spatial effect is approximately 5.


## Plotting the fitted trend: 
Since standard plotting functions in `R` work on regular grids, we have to interpolate the estimated trend to such a grid, using the `inla.mesh.project` mechanism:


```{r plotting the trend, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
proj_grid=inla.mesh.projector(mesh,xlim=range(bound$loc[,1]),ylim=range(bound$loc[,2]),
                              dims=c(200,200))

# The estimated posterior mean of the spatial effect at the mesh values is as follows:
est.spatial.mesh=fit$summary.random$spatial$mean

# We use the projector proj_grid to interpolate the spatial effect values to a regular grid:
image.plot(proj_grid$x,proj_grid$y,inla.mesh.project(proj_grid,field=est.spatial.mesh), asp = 1, xlab = "x (1000 km)", ylab = "y (1000 km)")
points(unique(xy_OBS),pch=19,cex=.25)
# lines(rbind(bound$loc,bound$loc[1,]),lwd=2)
lines(fr$x,fr$y,lwd=2)

# The posterior standard deviation (=uncertainty) of the spatial effect 
# at the mesh values is as follows:
sd.spatial.mesh=fit$summary.random$spatial$sd

# We use the projector proj_grid to interpolate the sd values to a regular grid:
image.plot(proj_grid$x,proj_grid$y,inla.mesh.project(proj_grid,field=sd.spatial.mesh), asp = 1, xlab = "x (1000 km)", ylab = "y (1000 km)")
points(unique(xy_OBS),pch=19,cex=.25)
lines(rbind(bound$loc,bound$loc[1,]),lwd=2)
lines(fr$x,fr$y,lwd=2)
```
Note: as expected, there is usually low uncertainty where we have many observations sites.

## Predictions

For making predictions of the trend over the full territory, we have to add the intercept to the latent spatial effect (here done in a "naive" way):

```{r plotting the trend surface, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
# Plot the trend surface:
image.plot(proj_grid$x,proj_grid$y,inla.mesh.project(proj_grid,field=est.spatial.mesh)+fit$summary.fixed$mean, asp = 1, xlab = "x (1000 km)", ylab = "y (1000 km)")
points(unique(xy_OBS),pch=19,cex=.25)
lines(fr$x,fr$y,lwd=2)
```


Alternatively, we could calculate the prediction on the grid in the very general way by adding NA data: ####

```{r Alternative plotting the trend surface, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
# Observation matrix to make the connection between mesh nodes and observation sites:
proj_grid=inla.mesh.projector(mesh,xlim=range(bound$loc[,1]),ylim=range(bound$loc[,2]),dims=c(100,100))

# Grid on wich we calculate the predictions:
xygrid=as.matrix(expand.grid(proj_grid$x,proj_grid$y))

# ¨Put prediction coordinates and observation coordinates into A:
A=inla.spde.make.A(mesh,loc=rbind(xygrid,xy_OBS))

# We add the intercept term 1, since in RINLA it's more comfortable to include the intercept explicitly.
covar.df=data.frame(intercept=1,x=c(xygrid[,1],xy_OBS[,1]),y=c(xygrid[,2],xy_OBS[,2]))

# Create the stack with all the data and indices: add NA data here
mystack=inla.stack(data=list(pm10=c(rep(NA,nrow(xygrid)),OBS_daily2014$PM10)),A=list(A,1),effects=list(idx.spatial,covar.df),tag="mytag")
```

# Prediction with posteriors

When fitting, we now set `compute=TRUE` (to calculate fitted and predicted values) and `link=1` (although only necessary when using non-identity link).

*NOTE:* running INLA can now take considerably longer since we calculate the posterior estimation `y.hat` for each observation point $y$ (`compute=TRUE`). Evaluation has been set to `FALSE` for producing the html document with `knit`. 

```{r Prediction with posteriors, echo=TRUE, eval=FALSE, warning=FALSE, message=FALSE, tidy=TRUE}
fit=inla(myformula,
         data=inla.stack.data(mystack),
         family="gaussian",
         control.predictor=list(A=inla.stack.A(mystack),compute=TRUE,link=1),
         control.inla=list(int.strategy="eb",strategy="gaussian"),
         verbose=FALSE,
         num.threads=num.thr)
summary(fit)
# save(fit,file="fit1.Rdata")
```


We now look at the outputs:

```{r Looking at outputs with posteriors, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
# load(file="fit1.Rdata")
# We find the positions of the prediction values (there may be several ways to do this...):
idx.pred=inla.stack.index(mystack,tag="mytag")$data[1:nrow(xygrid)]

# We extract predictions:
pred.grid=fit$summary.fitted.values$mean[idx.pred]

# We plot the gridded posterior means:
image.plot(proj_grid$x,proj_grid$y,matrix(pred.grid,ncol=100,nrow=100), asp = 1, xlab = "x (1000 km)", ylab = "y (1000 km)")
points(unique(xy_OBS),pch=19,cex=.25)
lines(fr$x,fr$y,lwd=2)

# We extract and plot standard erors of predictions:
pred.grid=fit$summary.fitted.values$sd[idx.pred]
image.plot(proj_grid$x,proj_grid$y,matrix(pred.grid,ncol=100,nrow=100), asp = 1, xlab = "x (1000 km)", ylab = "y (1000 km)")
points(unique(xy_OBS),pch=19,cex=.25)
lines(fr$x,fr$y,lwd=2)

#We check the residuals (here: data minus prediction) ####
n.data=nrow(OBS_daily2014) #number of data points
idx.data=inla.stack.index(mystack,tag="mytag")$data[(nrow(xygrid)+1):(nrow(xygrid)+n.data)]
resid=OBS_daily2014$PM10-fit$summary.fitted.values$mean[idx.data]
hist(resid,breaks=100,freq=F)
#We add the density of the fitted Gaussian likelihood to the plot:
#therefore, we first calculate the posterior mean estimate of the Gaussian standard deviation
#(based on the posterior density of the Gaussian precision):
prec2sd=function(prec){#function to transform precision to standard deviation
  sqrt(1/prec)
}
sd.likelihood=inla.emarginal(prec2sd,marginal=fit$marginals.hyperpar$`Precision for the Gaussian observations`)
sd.likelihood
xvals=-500+1:1000
lines(xvals,dnorm(xvals,sd=sd.likelihood),col="blue",lwd=2)
```

Conclusion: data are asymmetric and heavy-tailed (as opposed to our Gaussian response model). Alternatively, we could draw a QQ-plot. This looks not so good, but is not surprising since the model is very simple.

```{r Looking at qq-plot with posteriors, echo=TRUE, warning=FALSE, message=FALSE, tidy=TRUE}
qqplot(OBS_daily2014$PM10,fit$summary.fitted.values$mean[idx.data],xlab="observed",ylab="fitted",asp=1)
abline(0,1)
```













